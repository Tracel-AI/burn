# Getting Started

Burn is a deep learning framework in the Rust programming language. Therefore, 
one must understand the basic notions of Rust to use Burn. Reading the 
[Rust Book](https://doc.rust-lang.org/book/) is recommended, but don't worry if you're just starting
out. We provide context and reference to external resources when required.
Look out for the **ðŸ¦€ Rust Note** indicators.

## Installing Rust

To install Rust, refer to the
[installation page](https://doc.rust-lang.org/book/ch01-01-installation.html). It explains in
details the most convenient way to install Rust on your computer, the first step
to use Burn.

## Creating a Burn application

Once Rust is correctly installed, create a new Rust application by using Rust's build system and
package manager Cargo. It is automatically installed with Rust.

<details>
<summary><strong>ðŸ¦€ Cargo Cheat Sheet</strong></summary>

[Cargo](https://doc.rust-lang.org/cargo/) is a very useful tool to manage Rust projects.
It is used to compile your code
and download and build the libraries/packages your code depends on.

Below is a short cheat sheet of the main `cargo` commands you might use throughout this guide.

| Command             | Description                                                                                  |
| ------------------- | -------------------------------------------------------------------------------------------- |
| `cargo new` _path_  | Create a new Cargo package at the given _path_.                                           |
| `cargo add` _crate_ | Add dependencies to the Cargo.toml manifest file.                                            |
| `cargo build`       | Compile the local package and all of its dependencies (in debug mode, use `-r` for release). |
| `cargo check`       | Check the local package for compilation errors (much faster).                                |
| `cargo run`         | Run the local package binary (in debug mode, use `-r` for release).                                                                |

For more information, check 
[Hello, Cargo!](https://doc.rust-lang.org/book/ch01-03-hello-cargo.html) in the Rust Book.

</details><br>

In the directory of your choice, run the following:

```console
cargo new my_burn_app
```

This initializes the `my_burn_app` project directory with a `Cargo.toml` file and a `src`
directory with an auto-generated `main.rs` file inside. Head inside the directory.

```console
cd my_burn_app
```

Then, add Burn as a dependency:

```console
cargo add burn --features wgpu
```

Finally, compile the local package:

```console
cargo build
```

That's it, you're ready to start! You have a project configured with Burn and the WGPU backend,
which allows to execute low-level operations on any platform using the GPU.

## Writing a code snippet

The `src/main.rs` file was automatically generated by Cargo. Let's replace its content with:

```rust, ignore
use burn::backend::Wgpu;
use burn::tensor::Tensor;

// Type alias for the backend to use.
type Backend = Wgpu;

fn main() {
    // Here Rust infer the type of `device` to `WgpuDevice`.
    let device = Default::default();

    // Create two tensors, the first with explicit values
    // and the second filled with ones and using the same shape as the first
    let tensor_1 = Tensor::<Backend, 2>::from_data([[2., 3.], [4., 5.]], &device);
    let tensor_2 = Tensor::<Backend, 2>::ones_like(&tensor_1);

    // Print the element-wise addition (done with the WGPU backend) of the two tensors.
    println!("{}", tensor_1 + tensor_2);
}
```

<details>
<summary><strong>ðŸ¦€ Use Declarations</strong></summary>

To bring any of the Burn module or item into scope, a `use` declaration is added.

In the example above, we want to bring the `Tensor` struct and `Wgpu` backend into scope with the
following:

```rust, ignore
use burn::tensor::Tensor;
use burn::backend::Wgpu;
```

The same declaration could be written in a single statement
to simultaneously bind multiple paths with a common prefix:

```rust, ignore
use burn::{tensor::Tensor, backend::backend::Wgpu};
```

In this example, the common prefix is pretty short and there are only two items to bind locally.
Therefore, the first usage with two `use` declarations might be preferred. But know that both
examples are valid. For more details on the `use` keyword, take a look at
[this section](https://doc.rust-lang.org/book/ch07-04-bringing-paths-into-scope-with-the-use-keyword.html)
of the Rust Book or the
[Rust reference](https://doc.rust-lang.org/reference/items/use-declarations.html).

</details><br>

<details>
<summary><strong>ðŸ¦€ Generic Data Types</strong></summary>

If you're new to Rust, you may wonder why we use `Tensor::<Backend, 2>::...`.
That's because the `Tensor` struct is [generic](https://doc.rust-lang.org/book/ch10-01-syntax.html)
over multiple concrete data types. More specifically, a `Tensor` can be defined using three generic
parameters: the backend, the number of dimensions (rank) and the data type (defaults to `Float`).
Here, we only specify the backend and number of dimensions since `Float` is used by
default. For more details on the `Tensor` struct, see
[this section](./building-blocks/tensor.md).

Most of the time when generics are involved, the compiler can infer the generic parameters
automatically. In this case, the compiler needs a little help. This is usually done in one of
two ways: providing a type annotation or binding the gereneric parameter via the so-called _turbofish_ `::<>`
syntax. In the example above we used the _turbofish_ syntax, but we could have used type
annotations instead like this:

```rust, ignore
let tensor_1: Tensor<Backend, 2> = Tensor::from_data([[2., 3.], [4., 5.]]);
let tensor_2 = Tensor::ones_like(&tensor_1);
```

Notice that we provide a type annotation for the first tensor only and yet this
example still works. That's because the compiler correctly inferred that `tensor_2` has the same
generic parameters. The same could be done in the original example, but specifying the
parameters for both is more explicit.

</details><br>

By running `cargo run`, you should now see the result of the addition:

```console
Tensor {
  data:
[[3.0, 4.0],
 [5.0, 6.0]],
  shape:  [2, 2],
  device:  DefaultDevice,
  backend:  "wgpu",
  kind:  "Float",
  dtype:  "f32",
}
```

While the previous example is simple, the upcoming [Basic Workflow](./basic-workflow) section will walk you
through a more relevant example for deep learning applications.

## Using `prelude`

Burn comes with a variety of functionalities in its core library. When creating a new model or using an
existing one for inference, you need to import every single component you use, which is a
little verbose.

To address this, a `prelude` module is provided, allowing to easily import commonly used types
and macros in a single statement:

```rust, ignore
use burn::prelude::*;
```

which is equal to:

```rust, ignore
use burn::{
    config::Config,
    module::Module,
    nn,
    tensor::{
        backend::Backend, Bool, Device, ElementConversion, Float, Int, Shape, Tensor,
        TensorData,
    },
};
```

<div class="warning">

For simplicity, the subsequent chapters all use this form of importing
except for the [Building Blocks](./building-blocks) chapter where explicit importing aids to
grasp the usage of particular types and macros.

</div>
